{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca968bf7-2555-4c55-98a7-8258d044cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn.tree._criterion.Criterion size changed, may indicate binary incompatibility. Expected 352 from C header, got 752 from PyObject\n",
      "sklearn.tree._criterion.ClassificationCriterion size changed, may indicate binary incompatibility. Expected 368 from C header, got 1800 from PyObject\n",
      "sklearn.tree._criterion.RegressionCriterion size changed, may indicate binary incompatibility. Expected 360 from C header, got 1592 from PyObject\n",
      "sklearn.tree._splitter.Splitter size changed, may indicate binary incompatibility. Expected 360 from C header, got 1360 from PyObject\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.tree._utils' has no attribute 'Stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NearestNeighborMatch, MatchOptimizer, create_table_one\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpropensity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElasticNetPropensityModel\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     18\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/dataset/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulate_hidden_confounder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_uplift_classification\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthetic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_synthetic_preds, get_synthetic_preds_holdout\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthetic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_synthetic_summary, get_synthetic_summary_holdout\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthetic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter_plot_summary, scatter_plot_summary_holdout\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/dataset/synthetic.py:21\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     BaseXRegressor,\n\u001b[1;32m     17\u001b[0m     BaseRRegressor,\n\u001b[1;32m     18\u001b[0m     BaseSRegressor,\n\u001b[1;32m     19\u001b[0m     BaseTRegressor,\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausaltree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CausalTreeRegressor\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpropensity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElasticNetPropensityModel\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_gain, get_cumgain\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/inference/tree/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausaltree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CausalTreeRegressor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcausalforest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CausalRandomForestRegressor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m uplift_tree_string, uplift_tree_plot, plot_dist_tree_leaves_values\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/inference/tree/causal/causaltree.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausalml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_treatment_vector\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCausalDecisionTree\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tree_leaves_mask, timeit\n\u001b[1;32m     18\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausalml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/inference/tree/causal/_tree.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_sample_weight\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DepthFirstCausalTreeBuilder, BestFirstCausalTreeBuilder\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardMSE, CausalMSE, TTest\n\u001b[1;32m     19\u001b[0m CAUSAL_TREES_CRITERIA \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m: CausalMSE,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m: StandardMSE,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_test\u001b[39m\u001b[38;5;124m\"\u001b[39m: TTest,\n\u001b[1;32m     23\u001b[0m }\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_mskiera/master-thesis/thesis/lib64/python3.9/site-packages/causalml/inference/tree/causal/_builder.pyx:1\u001b[0m, in \u001b[0;36minit causalml.inference.tree.causal._builder\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.tree._utils' has no attribute 'Stack'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.match import NearestNeighborMatch, MatchOptimizer, create_table_one\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from causalml.dataset import *\n",
    "from causalml.metrics import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4874100e-85a3-498f-b681-e5fac9bb4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "print(importlib.metadata.version('causalml') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dfa697-a99a-473b-b418-0e359cbe760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bpi2017_filledLog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee0d22f-b844-41dc-88ba-42d742e31054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['treatment'] = df['treatment'].replace({'treated': 1, 'notTreated': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f2e75c2-6440-4c7f-990f-e88cc370be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment=df['treatment']\n",
    "X = df[['FirstWithdrawalAmount', 'NumberOfTerms', 'MonthlyCost', 'CreditScore', 'OfferedAmount']]\n",
    "y=df['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e1a28a-0987-4588-9c37-9b28ec2029d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.20577068]), array([0.20437408]), array([0.20716727]))\n",
      "ATE estimate: 0.206\n",
      "ATE lower bound: 0.204\n",
      "ATE upper bound: 0.207\n"
     ]
    }
   ],
   "source": [
    "# Ready-to-use S-Learner using LinearRegression\n",
    "learner_s = LRSRegressor()\n",
    "ate_s = learner_s.estimate_ate(X=features, treatment=df['treatment'], y=df['successful'])\n",
    "print(ate_s)\n",
    "print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))\n",
    "\n",
    "# After calling estimate_ate, add pretrain=True flag to skip training\n",
    "# This flag is applicable for other meta learner\n",
    "# ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y, pretrain=True)\n",
    "# print(ate_s)\n",
    "# print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "# print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "# print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09dbbf6f-8f7e-45d2-85d4-7aab1416c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Linear Regression): 0.21 (0.20, 0.21)\n",
      "Average Treatment Effect (XGBoost): 0.19 (0.18, 0.19)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.06 (0.06, 0.06)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Treatment Effect (Neural Network (MLP)): \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(te[\u001b[38;5;241m0\u001b[39m], lb[\u001b[38;5;241m0\u001b[39m], ub[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     16\u001b[0m xl \u001b[38;5;241m=\u001b[39m BaseXRegressor(learner\u001b[38;5;241m=\u001b[39mXGBRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m te, lb, ub \u001b[38;5;241m=\u001b[39m xl\u001b[38;5;241m.\u001b[39mestimate_ate(X, treatment, y, \u001b[43me\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Treatment Effect (BaseXRegressor using XGBoost): \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(te[\u001b[38;5;241m0\u001b[39m], lb[\u001b[38;5;241m0\u001b[39m], ub[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     20\u001b[0m rl \u001b[38;5;241m=\u001b[39m BaseRRegressor(learner\u001b[38;5;241m=\u001b[39mXGBRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LRSRegressor()\n",
    "te, lb, ub = lr.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Linear Regression): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "xg = XGBTRegressor(random_state=42)\n",
    "te, lb, ub = xg.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "# xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "# te, lb, ub = xl.estimate_ate(X, treatment, y, e)\n",
    "# print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "# rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "# te, lb, ub =  rl.estimate_ate(X=X, p=e, treatment=treatment, y=y)\n",
    "# print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
