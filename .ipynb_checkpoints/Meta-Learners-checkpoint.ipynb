{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca968bf7-2555-4c55-98a7-8258d044cfd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "\n",
    "import evaluationData\n",
    "\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.match import NearestNeighborMatch, MatchOptimizer, create_table_one\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from causalml.metrics import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4874100e-85a3-498f-b681-e5fac9bb4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "print(importlib.metadata.version('causalml') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a0d2ba-c230-4ffb-b502-6711dca4353d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BPIC2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dfa697-a99a-473b-b418-0e359cbe760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case:concept:name', 'NumberOfOffers', 'Action', 'org:resource',\n",
      "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
      "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
      "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
      "       'Selected', 'CreditScore', 'OfferedAmount', 'treatedCase',\n",
      "       'caseSuccesful', 'treatmentSuccess', 'offerNumber', 'offerSuccess',\n",
      "       'treatmentOffer', 'timeApplication', 'weekdayApplication'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>NumberOfOffers</th>\n",
       "      <th>Action</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>EventOrigin</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:LoanGoal</th>\n",
       "      <th>case:ApplicationType</th>\n",
       "      <th>...</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>OfferedAmount</th>\n",
       "      <th>treatedCase</th>\n",
       "      <th>caseSuccesful</th>\n",
       "      <th>treatmentSuccess</th>\n",
       "      <th>offerNumber</th>\n",
       "      <th>offerSuccess</th>\n",
       "      <th>treatmentOffer</th>\n",
       "      <th>timeApplication</th>\n",
       "      <th>weekdayApplication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>651433.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>651434.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>651435.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>651437.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.613</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>651438.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.620</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case:concept:name  NumberOfOffers  Action  org:resource  concept:name  \\\n",
       "0                0.0             1.0     0.0           0.0           4.0   \n",
       "1                0.0             1.0     4.0           0.0           8.0   \n",
       "2                0.0             1.0     0.0           0.0          22.0   \n",
       "3                0.0             1.0     1.0           0.0          22.0   \n",
       "4                0.0             1.0     0.0           0.0          21.0   \n",
       "\n",
       "   EventOrigin  lifecycle:transition  time:timestamp  case:LoanGoal  \\\n",
       "0          0.0                   1.0        651433.0           10.0   \n",
       "1          0.0                   1.0        651434.0           10.0   \n",
       "2          2.0                   3.0        651435.0           10.0   \n",
       "3          2.0                   6.0        651437.0           10.0   \n",
       "4          2.0                   3.0        651438.0           10.0   \n",
       "\n",
       "   case:ApplicationType  ...  CreditScore  OfferedAmount  treatedCase  \\\n",
       "0                   1.0  ...          0.0         5000.0          0.0   \n",
       "1                   1.0  ...          0.0         5000.0          0.0   \n",
       "2                   1.0  ...          0.0         5000.0          0.0   \n",
       "3                   1.0  ...          0.0         5000.0          0.0   \n",
       "4                   1.0  ...          0.0         5000.0          0.0   \n",
       "\n",
       "   caseSuccesful  treatmentSuccess  offerNumber  offerSuccess  treatmentOffer  \\\n",
       "0            0.0               0.0          1.0           0.0             0.0   \n",
       "1            0.0               0.0          1.0           0.0             0.0   \n",
       "2            0.0               0.0          1.0           0.0             0.0   \n",
       "3            0.0               0.0          1.0           0.0             0.0   \n",
       "4            0.0               0.0          1.0           0.0             0.0   \n",
       "\n",
       "   timeApplication  weekdayApplication  \n",
       "0            0.000                 2.0  \n",
       "1            0.061                 2.0  \n",
       "2            0.290                 2.0  \n",
       "3           66.613                 2.0  \n",
       "4           66.620                 2.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bpi2017_final.csv\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e5f8ea-c19a-4d6f-afe6-e53b254e5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['NumberOfOffers', 'Action', 'org:resource',\n",
    "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
    "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'CreditScore', 'OfferedAmount', 'offerNumber','timeApplication', 'weekdayApplication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2e75c2-6440-4c7f-990f-e88cc370be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment=df['treatmentOffer']\n",
    "X = df[feature_names]\n",
    "y=df['offerSuccess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dec6ef-a2bc-4602-bba8-974d55b03475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17406175 0.17406048 0.17405714 ... 0.07747542 0.07747561 0.07747409]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m p \u001b[38;5;241m=\u001b[39m p_model\u001b[38;5;241m.\u001b[39mfit_predict(X, treatment)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(p)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpropensity-score-MetaLearners\u001b[39m\u001b[38;5;124m'\u001b[39m, p)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "#propensity model for X- & R-Learner\n",
    "p_model = ElasticNetPropensityModel()\n",
    "p = p_model.fit_predict(X, treatment)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34496277-e227-4737-9235-d9f7d82f194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('propensity-score-MetaLearners', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a50ba0-ce99-4627-bb4e-a9f7bf0d7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17406175 0.17406048 0.17405714 ... 0.07747542 0.07747561 0.07747409]\n"
     ]
    }
   ],
   "source": [
    "p = np.load('propensity-score-MetaLearners.npy')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1a28a-0987-4588-9c37-9b28ec2029d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the S-Learner LinearRegression\n",
      "(array([0.06477474]), array([0.06185492]), array([0.06769455]))\n",
      "\n",
      "Using the XGBTRegressor class\n",
      "(array([0.18294639]), array([0.18202016]), array([0.18387262]))\n",
      "\n",
      "Using the BaseTRegressor class and using XGB (same result):\n",
      "(array([0.18294639]), array([0.18202016]), array([0.18387262]))\n",
      "\n",
      "Using the BaseTRegressor class and using Linear Regression (different result):\n",
      "(array([0.09409883]), array([0.09269185]), array([0.09550582]))\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "(array([0.51276654]), array([0.51179811]), array([0.51373498]))\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "(array([0.07960877]), array([0.0782071]), array([0.08101043]))\n"
     ]
    }
   ],
   "source": [
    "# Ready-to-use S-Learner using LinearRegression\n",
    "learner_s = LRSRegressor()\n",
    "ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('Using the S-Learner LinearRegression')\n",
    "print(ate_s)\n",
    "# print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "# print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "# print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))\n",
    "\n",
    "# Ready-to-use T-Learner using XGB\n",
    "learner_t = XGBTRegressor()\n",
    "ate_t = learner_t.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the XGBTRegressor class')\n",
    "print(ate_t)\n",
    "\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_t_xgb = BaseTRegressor(learner=XGBRegressor())\n",
    "ate_t_xgb = learner_t_xgb.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the BaseTRegressor class and using XGB (same result):')\n",
    "print(ate_t_xgb)\n",
    "\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_t_lr = BaseTRegressor(learner=LinearRegression())\n",
    "ate_t_lr= learner_t_lr.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the BaseTRegressor class and using Linear Regression (different result):')\n",
    "print(ate_t_lr)\n",
    "\n",
    "# X Learner with propensity score input\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_x_p_xgb = BaseXRegressor(learner=XGBRegressor())\n",
    "ate_x_p_xgb = learner_x_p_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "print('Using the BaseXRegressor class and using XGB:')\n",
    "print(ate_x_p_xgb)\n",
    "\n",
    "# X Learner with propensity score input\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_x_p_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ate_x_p_lr = learner_x_p_lr.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "print('\\nUsing the BaseXRegressor class and using Linear Regression:')\n",
    "print(ate_x_p_lr)\n",
    "\n",
    "# X Learner without propensity score input\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_x_xgb = BaseXRegressor(XGBRegressor())\n",
    "ate_x_xgb = learner_x_xgb.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('Using the BaseXRegressor class and using XGB without propensity score input:')\n",
    "print(ate_x_xgb)\n",
    "\n",
    "# X Learner without propensity score input\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_x_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ate_x_lr = learner_x_lr.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the BaseXRegressor class and using Linear Regression without propensity score input:')\n",
    "print(ate_x_lr)\n",
    "\n",
    "# R Learner with propensity score input\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_r_p_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "ate_r_p_xgb = learner_r_p_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "print('Using the BaseRRegressor class and using XGB:')\n",
    "print(ate_r_p_xgb)\n",
    "\n",
    "# R Learner with propensity score input\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_r_p_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ate_r_p_lr = learner_r_p_lr.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "print('Using the BaseRRegressor class and using Linear Regression:')\n",
    "print(ate_r_p_lr)\n",
    "\n",
    "# R Learner with propensity score input and random sample weight\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_r_pw_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "sample_weight = np.random.randint(1, 3, len(y))\n",
    "ate_r_pw_xgb = learner_r_pw_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p, sample_weight=sample_weight)\n",
    "print('Using the BaseRRegressor class with random weight and using XGB:')\n",
    "print(ate_r_pw_xgb)\n",
    "\n",
    "# R Learner without propensity score input\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_r_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "ate_r_xgb = learner_r_xgb.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('Using the BaseRRegressor class and using XGB without propensity score input:')\n",
    "print(ate_r_xgb)\n",
    "\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_r_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ate_r_lr = learner_r_lr.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('Using the BaseRRegressor class and using Linear Regression without propensity score input:')\n",
    "print(ate_r_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9af3b-57c1-4cf9-b713-d111449a4022",
   "metadata": {},
   "source": [
    "### 7. Calculate Individual Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2697d7-8fdf-4866-a700-081c77caa7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE S:  [[0.06477474]\n",
      " [0.06477474]\n",
      " [0.06477474]\n",
      " ...\n",
      " [0.06477474]\n",
      " [0.06477474]\n",
      " [0.06477474]]\n",
      "ITE T:  [[0.30053258]\n",
      " [0.18866764]\n",
      " [0.14396259]\n",
      " ...\n",
      " [0.00306845]\n",
      " [0.00248682]\n",
      " [0.00195444]]\n",
      "ITE XGB T:  [[0.30053258]\n",
      " [0.18866764]\n",
      " [0.14396259]\n",
      " ...\n",
      " [0.00306845]\n",
      " [0.00248682]\n",
      " [0.00195444]]\n",
      "ITE T RL:  [[0.17752653]\n",
      " [0.16730068]\n",
      " [0.18100416]\n",
      " ...\n",
      " [0.00463327]\n",
      " [0.01120845]\n",
      " [0.02505036]]\n"
     ]
    }
   ],
   "source": [
    "# S Learner\n",
    "learner_s = LRSRegressor()\n",
    "ite_s = learner_s.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE S: \", ite_s)\n",
    "\n",
    "# T Learner\n",
    "learner_t = BaseTRegressor(learner=XGBRegressor())\n",
    "ite_t = learner_t.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE T: \", ite_t)\n",
    "\n",
    "# T Learner feeding in XGB (same as above)\n",
    "learner_t_xgb = BaseTRegressor(learner=XGBRegressor())\n",
    "ite_t_xgb = learner_t_xgb.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE XGB T: \", ite_t_xgb)\n",
    "\n",
    "# T Learner LinearRegression\n",
    "learner_t_lr = BaseTRegressor(learner=LinearRegression())\n",
    "ite_t_lr= learner_t_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE T RL: \", ite_t_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "833dabcc-5923-4fd1-b6d2-f7650bccbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE X:  [[ 0.04489529]\n",
      " [ 0.02423898]\n",
      " [-0.00709323]\n",
      " ...\n",
      " [ 0.93208489]\n",
      " [ 0.93209036]\n",
      " [ 0.93024249]]\n",
      "ITE X (wihtout p):  [[ 0.03856069]\n",
      " [ 0.02042402]\n",
      " [-0.01083504]\n",
      " ...\n",
      " [ 0.89728747]\n",
      " [ 0.89700203]\n",
      " [ 0.89538468]]\n",
      "ITE X LR:  [[0.17752653]\n",
      " [0.16730068]\n",
      " [0.18100416]\n",
      " ...\n",
      " [0.00463327]\n",
      " [0.01120845]\n",
      " [0.02505036]]\n",
      "ITE X LR (wihtout p):  [[0.17752653]\n",
      " [0.16730068]\n",
      " [0.18100416]\n",
      " ...\n",
      " [0.00463327]\n",
      " [0.01120845]\n",
      " [0.02505036]]\n"
     ]
    }
   ],
   "source": [
    "# X Learner with propensity score input\n",
    "learner_x_p = BaseXRegressor(learner=XGBRegressor())\n",
    "ite_x_p = learner_x_p.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE X: \", ite_x_p)\n",
    "\n",
    "# X Learner without propensity score input\n",
    "learner_x = BaseXRegressor(learner=XGBRegressor())\n",
    "ite_x = learner_x.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE X (wihtout p): \", ite_x)\n",
    "\n",
    "# X Learner LR with propensity score input\n",
    "learner_x_p_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ite_x_p_lr = learner_x_p_lr.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE X LR: \", ite_x_p_lr)\n",
    "\n",
    "# X Learner LR without propensity score input\n",
    "learner_x_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ite_x_lr = learner_x_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE X LR (wihtout p): \", ite_x_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14269310-636d-4096-8bc7-206eac620c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITE R:  [[-0.00456186]\n",
      " [-0.00456186]\n",
      " [-0.00231892]\n",
      " ...\n",
      " [-0.00086562]\n",
      " [-0.00025799]\n",
      " [ 0.00103475]]\n",
      "ITE R (without p):  [[ 0.09482569]\n",
      " [ 0.11773356]\n",
      " [ 0.10719296]\n",
      " ...\n",
      " [-0.00409879]\n",
      " [-0.00573711]\n",
      " [-0.00405265]]\n",
      "ITE R LR:  [[0.12940255]\n",
      " [0.12646731]\n",
      " [0.12844959]\n",
      " ...\n",
      " [0.0006854 ]\n",
      " [0.0058162 ]\n",
      " [0.01361836]]\n",
      "ITE R (with random weight):  [[-0.02148819]\n",
      " [-0.02148819]\n",
      " [-0.01485084]\n",
      " ...\n",
      " [-0.02504064]\n",
      " [-0.02504064]\n",
      " [-0.02160337]]\n"
     ]
    }
   ],
   "source": [
    "# R Learner with propensity score input \n",
    "learner_r = BaseRRegressor(learner=XGBRegressor())\n",
    "ite_r = learner_r.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE R: \", ite_r)\n",
    "\n",
    "# R Learner without propensity score input\n",
    "learner_r_no_p = BaseRRegressor(learner=XGBRegressor())\n",
    "ite_r_no_p = learner_r_no_p.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE R (without p): \", ite_r_no_p)\n",
    "\n",
    "# R Learner LR with propensity score input\n",
    "learner_r_p_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ite_r_p_lr = learner_r_p_lr.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE R LR: \", ite_r_p_lr)\n",
    "\n",
    "# R Learner with propensity score input and random sample weight\n",
    "learner_r_pw_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "sample_weight = np.random.randint(1, 3, len(y))\n",
    "ite_r_pw_xgb = learner_r_pw_xgb.fit_predict(X=X, treatment=treatment, y=y, p=p, sample_weight=sample_weight)\n",
    "print(\"ITE R (with random weight): \", ite_r_pw_xgb)\n",
    "\n",
    "# # R Learner LR without propensity score input\n",
    "# learner_r_lr = BaseRRegressor(learner=LinearRegression())\n",
    "# ite_r_lr = learner_r_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "# print(\"ITE R LR (without p): \", ite_r_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e39aa-da63-4354-ae43-562aa2c8d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R Learner LR without propensity score input\n",
    "learner_r_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ite_r_lr = learner_r_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE R LR (without p): \", ite_r_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc156e9-11f3-416d-b0c5-eecac7884b89",
   "metadata": {},
   "source": [
    "### Other Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cec766e-9e28-4c5f-a097-f8f3fc5c67f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Neural Network (MLP)): 0.14 (0.13, 0.14)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m te_nn, lb_nn, ub_nn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mestimate_ate(X, treatment, y)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Treatment Effect (Neural Network (MLP)): \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(te_nn[\u001b[38;5;241m0\u001b[39m], lb_nn[\u001b[38;5;241m0\u001b[39m], ub_nn[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mte_nn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "te_nn, lb_nn, ub_nn = nn.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te_nn[0], lb_nn[0], ub_nn[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc8347c-f3db-43b0-b252-029bd90fb740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13711836145561046\n"
     ]
    }
   ],
   "source": [
    "print(te_nn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35719511-0f59-42d8-adb5-ccf3290dcb5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Input Results in Results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e30659-8497-41d4-825d-5a2130350321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_list = {'Method': ['S-Learner LR', 'XGBTRegressor', 'BaseTRegressor XGB', 'BaseTRegressor LR', 'BaseXRegressor XGB', 'BaseXRegressor LR',\n",
    "#                           'BaseXRegressor XGB (without propensity score)','BaseXRegressor LR (without propensity score)', 'BaseRRegressor XGB', \n",
    "#                           'BaseRRegressor LR', 'BaseRRegressor XGB (with random weight)', 'BaseRRegressor XGB (without propensity score)',\n",
    "#                          'BaseRRegressor LR (without propensity score)', 'Neural Network (MLP)'],\n",
    "#         'ATE': [ate_s[0][0], ate_t[0][0], ate_t_xgb[0][0], ate_t_lr[0][0], ate_x_p_xgb[0][0], ate_x_p_lr[0][0], ate_x_xgb[0][0], ate_x_lr[0][0], ate_r_p_xgb[0][0], ate_r_p_lr[0][0], ate_r_pw_xgb[0][0], ate_r_xgb[0][0], ate_r_lr[0][0], te_nn[0][0]],\n",
    "#         'ITE': [ite_s, ite_t, ite_t_xgb, ite_t_lr, ite_x_p,  ite_x_p_lr, ite_x, ite_x_lr, ite_r, ite_r_p_lr, ite_r_pw_xgb, ite_r_no_p, ite_r_lr, '']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6e0800-8a12-47cb-a686-605673ea475c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_r = [ite_r, ite_r_p_lr, ite_r_pw_xgb, ite_r_no_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dd1f2f-905d-42f7-9a41-3cb2e1e96159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: -2.841172695159912\n",
      "First Quartile: -0.022177141159772873\n",
      "Median: -0.0011553335934877396\n",
      "Third Quartile: 0.022602353245019913\n",
      "Maximum: 1.593336582183838\n",
      "Interquartile Range: 0.044779494404792786\n",
      "Upper Bound (Outliers): 0.08977159485220909\n",
      "Lower Bound (Outliers): -0.08934638276696205\n",
      "Outliers: [ 0.09258621  0.09225269  0.09225269 ... -0.14480454 -0.14992988\n",
      " -0.14992988]\n",
      "Minimum: -0.6539629778797732\n",
      "First Quartile: -0.014001676778572877\n",
      "Median: 0.02244088467886033\n",
      "Third Quartile: 0.08991063850769189\n",
      "Maximum: 0.29162906073547185\n",
      "Interquartile Range: 0.10391231528626477\n",
      "Upper Bound (Outliers): 0.24577911143708903\n",
      "Lower Bound (Outliers): -0.16987014970797004\n",
      "Outliers: [-0.19172352 -0.19465876 -0.19267647 ... -0.20314153 -0.20943951\n",
      " -0.20714403]\n",
      "Minimum: -3.097541332244873\n",
      "First Quartile: -0.020540252327919006\n",
      "Median: -0.0008536885143257678\n",
      "Third Quartile: 0.021109196357429028\n",
      "Maximum: 1.5432970523834229\n",
      "Interquartile Range: 0.041649448685348034\n",
      "Upper Bound (Outliers): 0.08358336938545108\n",
      "Lower Bound (Outliers): -0.08301442535594106\n",
      "Outliers: [-0.08607285 -0.09899605 -0.09935959 ... -0.08912868 -0.19373761\n",
      " -0.08625615]\n",
      "Minimum: -5.4697980880737305\n",
      "First Quartile: -0.026043339632451534\n",
      "Median: -0.0029713185504078865\n",
      "Third Quartile: 0.02292294055223465\n",
      "Maximum: 1.5205625295639038\n",
      "Interquartile Range: 0.048966280184686184\n",
      "Upper Bound (Outliers): 0.09637236082926393\n",
      "Lower Bound (Outliers): -0.09949275990948081\n",
      "Outliers: [0.11773356 0.10719296 0.10778749 ... 0.11989013 0.13302368 0.1051708 ]\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "for i in list_r:\n",
    "\n",
    "    # Calculate statistics\n",
    "    data = np.reshape(i, -1)\n",
    "    minimum = np.min(data)\n",
    "    first_quartile = np.percentile(data, 25)\n",
    "    median = np.median(data)\n",
    "    third_quartile = np.percentile(data, 75)\n",
    "    maximum = np.max(data)\n",
    "    \n",
    "    # Interquartile range (IQR)\n",
    "    iqr = third_quartile - first_quartile\n",
    "    \n",
    "    # Define upper and lower bounds for outliers\n",
    "    upper_bound = third_quartile + 1.5 * iqr\n",
    "    lower_bound = first_quartile - 1.5 * iqr\n",
    "    \n",
    "    # Detect outliers\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    # Print the statistics\n",
    "    print(\"Minimum:\", minimum)\n",
    "    print(\"First Quartile:\", first_quartile)\n",
    "    print(\"Median:\", median)\n",
    "    print(\"Third Quartile:\", third_quartile)\n",
    "    print(\"Maximum:\", maximum)\n",
    "    print(\"Interquartile Range:\", iqr)\n",
    "    print(\"Upper Bound (Outliers):\", upper_bound)\n",
    "    print(\"Lower Bound (Outliers):\", lower_bound)\n",
    "    print(\"Outliers:\", outliers)\n",
    "\n",
    "    exec(f'boxplot_r_{y} = [minimum, first_quartile, median, third_quartile, maximum, iqr, upper_bound, lower_bound]')\n",
    "    y +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdcd38c-92ce-4ba2-beaa-d5c1f923f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list_s_t = {'Method': ['S-Learner LR', 'XGBTRegressor', 'BaseTRegressor XGB', 'BaseTRegressor LR'],\n",
    "        'ATE': [ite_s.mean(), ite_t.mean(), ite_t_xgb.mean(), ite_t_lr.mean()],\n",
    "        'ITE': [boxplot_1, boxplot_2, boxplot_3, boxplot_4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b3cd2bb-ee9f-4c3e-8468-b53b1cad3843",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list_x = {'Method': ['BaseXRegressor XGB', 'BaseXRegressor LR', 'BaseXRegressor XGB (without propensity score)','BaseXRegressor LR (without propensity score)'],\n",
    "        'ATE': [ite_x_p.mean(),  ite_x_p_lr.mean(), ite_x.mean(), ite_x_lr.mean()],\n",
    "        'ITE': [boxplot_x_1,  boxplot_x_2, boxplot_x_3, boxplot_x_4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846ca282-9fa8-4862-84fb-264060410d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list_r = {'Method': ['BaseRRegressor XGB', 'BaseRRegressor LR', 'BaseRRegressor XGB (with random weight)', 'BaseRRegressor XGB (without propensity score)'],\n",
    "        'ATE': [ite_r.mean(), ite_r_p_lr.mean(), ite_r_pw_xgb.mean(), ite_r_no_p.mean()],\n",
    "        'ITE': [boxplot_r_1, boxplot_r_2, boxplot_r_3, boxplot_r_4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5217872-c22c-4347-9c76-a19650e2b57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           method       ATE  \\\n",
      "0                               Linear Regression  0.449046   \n",
      "1                                       Double ML  0.471019   \n",
      "2                                             IPW  0.311352   \n",
      "3                                       IPW Hajek  0.311352   \n",
      "4                                  IPW Stabalized  0.311352   \n",
      "5                       Propensity Score Matching -0.179289   \n",
      "6                               Distance Matching  0.630322   \n",
      "7                                          IPW LR  0.149171   \n",
      "8                                       CausalEGM  0.124771   \n",
      "9                                     Causal Tree  0.034357   \n",
      "10                                    cforest_mse  0.087602   \n",
      "11                                   cforest_cmse  0.301697   \n",
      "12                             cforest_cmse_p=0.5  0.032615   \n",
      "13                        cforest_cmse_p=0.5_md=3  0.042756   \n",
      "14                                  cforest_ttest  0.130985   \n",
      "15             Accelerated Bayesian Causal Forest  0.049235   \n",
      "16                                   S-Learner LR  0.064775   \n",
      "17                                  XGBTRegressor  0.182946   \n",
      "18                             BaseTRegressor XGB  0.182946   \n",
      "19                              BaseTRegressor LR  0.094099   \n",
      "20                             BaseXRegressor XGB  0.512767   \n",
      "21                              BaseXRegressor LR  0.079609   \n",
      "22  BaseXRegressor XGB (without propensity score)  0.539519   \n",
      "23   BaseXRegressor LR (without propensity score)  0.084548   \n",
      "24                                           TMLE -0.000583   \n",
      "25                              TMLE Standardized -0.000868   \n",
      "26                            TMLE (with weights)  0.031268   \n",
      "27                             BaseRRegressor XGB  0.001693   \n",
      "28                              BaseRRegressor LR  0.031397   \n",
      "29        BaseRRegressor XGB (with random weight)  0.002552   \n",
      "30  BaseRRegressor XGB (without propensity score)  0.000052   \n",
      "31                           Neural Network (MLP)  0.137118   \n",
      "32                                         BCAUSS  0.015102   \n",
      "33                                      Dragonnet  0.162678   \n",
      "34                                          CEVAE -0.065165   \n",
      "\n",
      "                                                  ITE         Library  \\\n",
      "0                                                 NaN           DoWhy   \n",
      "1   [0.0, 0.0, 0.0, 0.9730893270729309, 1.24351258...           DoWhy   \n",
      "2                                                 NaN           DoWhy   \n",
      "3                                                 NaN           DoWhy   \n",
      "4                                                 NaN           DoWhy   \n",
      "5                                                 NaN           DoWhy   \n",
      "6                                                 NaN           DoWhy   \n",
      "7                                                 NaN       Causallib   \n",
      "8                                                 NaN       CausalEGM   \n",
      "9   [ 0.01388495  0.01388495  0.01388495 ...  0.18...        CausalML   \n",
      "10  862609     0.009281\\n1158138    0.155046\\n6033...        CausalML   \n",
      "11  862609     0.534503\\n1158138    0.267160\\n6033...        CausalML   \n",
      "12  862609    -0.032847\\n1158138   -0.032847\\n6033...        CausalML   \n",
      "13  862609    -0.072982\\n1158138   -0.072982\\n6033...        CausalML   \n",
      "14  862609     0.020529\\n1158138    0.090639\\n6033...        CausalML   \n",
      "15  [-0.09794314  0.14720209  0.17394319 ...  0.16...  xbcausalforest   \n",
      "16  [0.06477473769604769, 0.06477473769604813, 0.0...        CausalML   \n",
      "17  [-1.247403621673584, -0.007445007562637329, 0....        CausalML   \n",
      "18  [-1.247403621673584, -0.007445007562637329, 0....        CausalML   \n",
      "19  [-0.7549372243351995, 0.017519640303828188, 0....        CausalML   \n",
      "20  [-0.5197197980772417, 0.14606450637986346, 0.5...        CausalML   \n",
      "21  [-0.7549372243359451, 0.016062774379361974, 0....        CausalML   \n",
      "22  [-0.5114930704305567, 0.1463220536527003, 0.68...        CausalML   \n",
      "23  [-0.7549372243358587, 0.017081473269835855, 0....        CausalML   \n",
      "24                                                NaN       Causallib   \n",
      "25                                                NaN       Causallib   \n",
      "26                                                NaN       Causallib   \n",
      "27  [-2.841172695159912, -0.022177141159772873, -0...        CausalML   \n",
      "28  [-0.6539629778797732, -0.014001676778572877, 0...        CausalML   \n",
      "29  [-3.097541332244873, -0.020540252327919006, -0...        CausalML   \n",
      "30  [-5.4697980880737305, -0.026043339632451534, -...        CausalML   \n",
      "31                                                NaN        CausalML   \n",
      "32                                                NaN          BCAUSS   \n",
      "33  [[0.16267785]\\n [0.16267785]\\n [0.16267785]\\n ...        CausalML   \n",
      "34                                                NaN        CausalML   \n",
      "\n",
      "          Method Type  \n",
      "0   Linear Regression  \n",
      "1                DML?  \n",
      "2                 IPW  \n",
      "3                 IPW  \n",
      "4                 IPW  \n",
      "5            Matching  \n",
      "6            Matching  \n",
      "7                 IPW  \n",
      "8       Deep Learning  \n",
      "9              Uplift  \n",
      "10             Uplift  \n",
      "11             Uplift  \n",
      "12             Uplift  \n",
      "13             Uplift  \n",
      "14             Uplift  \n",
      "15             Uplift  \n",
      "16       Meta-Learner  \n",
      "17       Meta-Learner  \n",
      "18       Meta-Learner  \n",
      "19       Meta-Learner  \n",
      "20       Meta-Learner  \n",
      "21       Meta-Learner  \n",
      "22       Meta-Learner  \n",
      "23       Meta-Learner  \n",
      "24               TMLE  \n",
      "25               TMLE  \n",
      "26               TMLE  \n",
      "27       Meta-Learner  \n",
      "28       Meta-Learner  \n",
      "29       Meta-Learner  \n",
      "30       Meta-Learner  \n",
      "31      Deep Learning  \n",
      "32      Deep Learning  \n",
      "33      Deep Learning  \n",
      "34      Deep Learning  \n",
      "Stored 'df_results' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store -r df_results\n",
    "lib = \"CausalML\"\n",
    "result_list = result_list_r\n",
    "\n",
    "for i in range(len(result_list['Method'])):\n",
    "    method = result_list['Method'][i]\n",
    "    ate = result_list['ATE'][i]\n",
    "    ite = result_list['ITE'][i]\n",
    "\n",
    "    if method in df_results['method'].values:\n",
    "         # If the method is already in the DataFrame, update the ATE and ITE columns\n",
    "        df_results.loc[df_results['method'] == method, 'ATE'] = ate\n",
    "        index = df_results[df_results['method'] == method].index[0]\n",
    "        df_results.at[index, 'ITE'] = ite\n",
    "        df_results.loc[df_results['method'] == method, 'Library'] = lib\n",
    "    else:\n",
    "        # If the method is not in the DataFrame, add a new row\n",
    "        df_results = df_results._append({'method': method, 'ATE': ate, 'ITE': ite, 'Library': lib}, ignore_index=True)\n",
    "\n",
    "print(df_results)\n",
    "%store df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f9f69d-2667-4a8f-8e52-eaaae6e42725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           method       ATE  \\\n",
      "0                               Linear Regression  0.449046   \n",
      "1                                       Double ML  0.471019   \n",
      "2                                             IPW  0.311352   \n",
      "3                                       IPW Hajek  0.311352   \n",
      "4                                  IPW Stabalized  0.311352   \n",
      "5                       Propensity Score Matching -0.179289   \n",
      "6                               Distance Matching  0.630322   \n",
      "7                                          IPW LR  0.149171   \n",
      "8                                       CausalEGM  0.124771   \n",
      "9                                     Causal Tree  0.034357   \n",
      "10                                    cforest_mse  0.087602   \n",
      "11                                   cforest_cmse  0.301697   \n",
      "12                             cforest_cmse_p=0.5  0.032615   \n",
      "13                        cforest_cmse_p=0.5_md=3  0.042756   \n",
      "14                                  cforest_ttest  0.130985   \n",
      "15             Accelerated Bayesian Causal Forest  0.049235   \n",
      "16                                   S-Learner LR  0.064775   \n",
      "17                                  XGBTRegressor  0.182946   \n",
      "18                             BaseTRegressor XGB  0.182946   \n",
      "19                              BaseTRegressor LR  0.094099   \n",
      "20                             BaseXRegressor XGB  0.512767   \n",
      "21                              BaseXRegressor LR  0.079609   \n",
      "22  BaseXRegressor XGB (without propensity score)  0.539519   \n",
      "23   BaseXRegressor LR (without propensity score)  0.084548   \n",
      "24                                           TMLE -0.000583   \n",
      "25                              TMLE Standardized -0.000868   \n",
      "26                            TMLE (with weights)  0.031268   \n",
      "27                             BaseRRegressor XGB  0.002483   \n",
      "28                              BaseRRegressor LR  0.031397   \n",
      "29        BaseRRegressor XGB (with random weight)  0.000822   \n",
      "30  BaseRRegressor XGB (without propensity score)  0.000662   \n",
      "31                           Neural Network (MLP)  0.137118   \n",
      "\n",
      "                                                  ITE         Library  other  \n",
      "0                                                 NaN           DoWhy    NaN  \n",
      "1   [0.         0.         0.         ... 0.952180...           DoWhy    NaN  \n",
      "2                                                 NaN           DoWhy    NaN  \n",
      "3                                                 NaN           DoWhy    NaN  \n",
      "4                                                 NaN           DoWhy    NaN  \n",
      "5                                                 NaN           DoWhy    NaN  \n",
      "6                                                 NaN           DoWhy    NaN  \n",
      "7                                                 NaN       Causallib    NaN  \n",
      "8   [0.176025390625, 0.17529296875, 0.17529296875,...       CausalEGM    NaN  \n",
      "9   [0.013884954117139914, 0.013884954117139914, 0...        CausalML    NaN  \n",
      "10  862609     0.009281\n",
      "1158138    0.155046\n",
      "603398...        CausalML    NaN  \n",
      "11  862609     0.534503\n",
      "1158138    0.267160\n",
      "603398...        CausalML    NaN  \n",
      "12  862609    -0.032847\n",
      "1158138   -0.032847\n",
      "603398...        CausalML    NaN  \n",
      "13  862609    -0.072982\n",
      "1158138   -0.072982\n",
      "603398...        CausalML    NaN  \n",
      "14  862609     0.020529\n",
      "1158138    0.090639\n",
      "603398...        CausalML    NaN  \n",
      "15  [-0.09794314078138917, 0.14720208508268195, 0....  xbcausalforest    NaN  \n",
      "16  [[0.06477473769604813], [0.06477473769604813],...        CausalML    NaN  \n",
      "17  [[0.30053257942199707], [0.1886676400899887], ...        CausalML    NaN  \n",
      "18  [[0.30053257942199707], [0.1886676400899887], ...        CausalML    NaN  \n",
      "19  [[0.17752653031569782], [0.16730067903052004],...        CausalML    NaN  \n",
      "20  [[0.04489528542438478], [0.02423897893105312],...        CausalML    NaN  \n",
      "21  [[0.17752653031556137], [0.16730067903044], [0...        CausalML    NaN  \n",
      "22  [[0.038560691259585944], [0.020424017430629743...        CausalML    NaN  \n",
      "23  [[0.17752653031556065], [0.16730067903042609],...        CausalML    NaN  \n",
      "24                                                NaN       Causallib    NaN  \n",
      "25                                                NaN       Causallib    NaN  \n",
      "26                                                NaN       Causallib    NaN  \n",
      "27  [[0.030068019405007362], [0.03118271194398403]...        CausalML    NaN  \n",
      "28  [[0.12941571547856617], [0.12646330343137674],...        CausalML    NaN  \n",
      "29  [[0.014185604639351368], [0.014680038206279278...        CausalML    NaN  \n",
      "30  [[0.10782991349697113], [0.12393194437026978],...        CausalML    NaN  \n",
      "31                                                           CausalML    NaN  \n",
      "Stored 'df_results' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store -r df_results\n",
    "lib = \"CausalML\"\n",
    "result_list = result_list_r_nn\n",
    "\n",
    "for i in range(len(result_list['Method'])):\n",
    "    method = result_list['Method'][i]\n",
    "    ate = result_list['ATE'][i]\n",
    "    ite = result_list['ITE'][i]\n",
    "\n",
    "    if method in df_results['method'].values:\n",
    "         # If the method is already in the DataFrame, update the ATE and ITE columns\n",
    "        df_results.loc[df_results['method'] == method, 'ATE'] = ate\n",
    "        df_results.loc[df_results['method'] == method, 'ITE'] = [ite]\n",
    "        df_results.loc[df_results['method'] == method, 'Library'] = lib\n",
    "    else:\n",
    "        # If the method is not in the DataFrame, add a new row\n",
    "        df_results = df_results._append({'method': method, 'ATE': ate, 'ITE': ite, 'Library': lib}, ignore_index=True)\n",
    "\n",
    "print(df_results)\n",
    "%store df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318934f6-00c1-4f19-90a2-21d62b75afe8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf61154-4daa-49ef-ad8a-13f2db49606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth = pd.read_csv(\"synthetic_dataset.csv\")\n",
    "df_synth.head()\n",
    "synthetic_features = ['NumberOfOffers', 'concept:name',\n",
    "       'lifecycle:transition', 'time:timestamp', 'elementId', 'resourceId',\n",
    "       'weekdayApplication', 'timeApplication']\n",
    "treatment=df_synth['treatment']\n",
    "X = df_synth[synthetic_features]\n",
    "y=df_synth['treatmentSuccess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c590bb8-2003-4808-8950-48f28f8054d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48723344 0.48719778 0.48721561 ... 0.26391789 0.26389016 0.26390402]\n"
     ]
    }
   ],
   "source": [
    "#propensity model for X- & R-Learner\n",
    "p_model = ElasticNetPropensityModel()\n",
    "p = p_model.fit_predict(X, treatment)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6668e76b-6c59-4a13-83be-d84587194850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Neural Network (MLP)): 2.00 (2.00, 2.00)\n",
      "ITE S:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE T:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE XGB T:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE T RL:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE X:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE X (wihtout p):  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE X LR:  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE X LR (wihtout p):  [[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n",
      "ITE R:  [[3.62236483e-06]\n",
      " [3.62236483e-06]\n",
      " [3.62236483e-06]\n",
      " ...\n",
      " [3.62236483e-06]\n",
      " [3.62236483e-06]\n",
      " [3.62236483e-06]]\n",
      "ITE R (without p):  [[3.68120891e-06]\n",
      " [3.68120891e-06]\n",
      " [3.68120891e-06]\n",
      " ...\n",
      " [3.68120891e-06]\n",
      " [3.68120891e-06]\n",
      " [3.68120891e-06]]\n",
      "ITE R LR:  [[0.56567101]\n",
      " [0.56207732]\n",
      " [0.56387416]\n",
      " ...\n",
      " [1.48490208]\n",
      " [1.48130838]\n",
      " [1.48310523]]\n",
      "ITE R (with random weight):  [[3.62227593e-06]\n",
      " [3.62227593e-06]\n",
      " [3.62227593e-06]\n",
      " ...\n",
      " [3.62227593e-06]\n",
      " [3.62227593e-06]\n",
      " [3.62227593e-06]]\n",
      "ITE R LR (without p):  [[0.75956197]\n",
      " [0.75593824]\n",
      " [0.7577501 ]\n",
      " ...\n",
      " [1.42559988]\n",
      " [1.42197615]\n",
      " [1.42378802]]\n"
     ]
    }
   ],
   "source": [
    "nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "te_nn, lb_nn, ub_nn = nn.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te_nn[0], lb_nn[0], ub_nn[0]))\n",
    "# S Learner\n",
    "learner_s = LRSRegressor()\n",
    "ite_s = learner_s.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE S: \", ite_s)\n",
    "\n",
    "# T Learner\n",
    "learner_t = BaseTRegressor(learner=XGBRegressor())\n",
    "ite_t = learner_t.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE T: \", ite_t)\n",
    "\n",
    "# T Learner feeding in XGB (same as above)\n",
    "learner_t_xgb = BaseTRegressor(learner=XGBRegressor())\n",
    "ite_t_xgb = learner_t_xgb.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE XGB T: \", ite_t_xgb)\n",
    "\n",
    "# T Learner LinearRegression\n",
    "learner_t_lr = BaseTRegressor(learner=LinearRegression())\n",
    "ite_t_lr= learner_t_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE T RL: \", ite_t_lr)\n",
    "# X Learner with propensity score input\n",
    "learner_x_p = BaseXRegressor(learner=XGBRegressor())\n",
    "ite_x_p = learner_x_p.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE X: \", ite_x_p)\n",
    "\n",
    "# X Learner without propensity score input\n",
    "learner_x = BaseXRegressor(learner=XGBRegressor())\n",
    "ite_x = learner_x.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE X (wihtout p): \", ite_x)\n",
    "\n",
    "# X Learner LR with propensity score input\n",
    "learner_x_p_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ite_x_p_lr = learner_x_p_lr.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE X LR: \", ite_x_p_lr)\n",
    "\n",
    "# X Learner LR without propensity score input\n",
    "learner_x_lr = BaseXRegressor(learner=LinearRegression())\n",
    "ite_x_lr = learner_x_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE X LR (wihtout p): \", ite_x_lr)\n",
    "# R Learner with propensity score input \n",
    "learner_r = BaseRRegressor(learner=XGBRegressor())\n",
    "ite_r = learner_r.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE R: \", ite_r)\n",
    "\n",
    "# R Learner without propensity score input\n",
    "learner_r_no_p = BaseRRegressor(learner=XGBRegressor())\n",
    "ite_r_no_p = learner_r_no_p.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE R (without p): \", ite_r_no_p)\n",
    "\n",
    "# R Learner LR with propensity score input\n",
    "learner_r_p_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ite_r_p_lr = learner_r_p_lr.fit_predict(X=X, treatment=treatment, y=y, p=p)\n",
    "print(\"ITE R LR: \", ite_r_p_lr)\n",
    "\n",
    "# R Learner with propensity score input and random sample weight\n",
    "learner_r_pw_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "sample_weight = np.random.randint(1, 3, len(y))\n",
    "ite_r_pw_xgb = learner_r_pw_xgb.fit_predict(X=X, treatment=treatment, y=y, p=p, sample_weight=sample_weight)\n",
    "print(\"ITE R (with random weight): \", ite_r_pw_xgb)\n",
    "\n",
    "# R Learner LR without propensity score input\n",
    "learner_r_lr = BaseRRegressor(learner=LinearRegression())\n",
    "ite_r_lr = learner_r_lr.fit_predict(X=X, treatment=treatment, y=y)\n",
    "print(\"ITE R LR (without p): \", ite_r_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4348a3b-f62a-46f7-86b4-c987edc96033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_metrics\n",
    "synth_ite_list = [ite_s, ite_t, ite_t_xgb, ite_t_lr, ite_x_p,  ite_x_p_lr, ite_x, ite_x_lr, ite_r, ite_r_p_lr, ite_r_pw_xgb, ite_r_no_p]\n",
    "y=1\n",
    "synth_true_ate = 2\n",
    "for i in synth_ite_list:\n",
    "    boxplot = evaluation_metrics.boxplot_ite(i)\n",
    "    exec(f'boxplot_synth_{y} = boxplot')\n",
    "    metric = evaluation_metrics.evaluation_metrics(synth_true_ate, i)\n",
    "    exec(f'metric_synth_{y} = metric')\n",
    "    y +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3953dd9b-425e-47bd-bf8a-9dbf27cc1e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 1.999999999999998\n",
      "First Quartile: 1.9999999999999987\n",
      "Median: 1.9999999999999987\n",
      "Third Quartile: 1.999999999999999\n",
      "Maximum: 1.9999999999999993\n",
      "Interquartile Range: 2.220446049250313e-16\n",
      "Upper Bound (Outliers): 1.9999999999999991\n",
      "Lower Bound (Outliers): 1.9999999999999982\n",
      "Outliers: [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 2.0\n",
      "First Quartile: 2.0\n",
      "Median: 2.0\n",
      "Third Quartile: 2.0\n",
      "Maximum: 2.0\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 2.0\n",
      "Lower Bound (Outliers): 2.0\n",
      "Outliers: []\n",
      "Minimum: 3.6223518691258505e-06\n",
      "First Quartile: 3.6223518691258505e-06\n",
      "Median: 3.6223518691258505e-06\n",
      "Third Quartile: 3.6223518691258505e-06\n",
      "Maximum: 3.6223518691258505e-06\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 3.6223518691258505e-06\n",
      "Lower Bound (Outliers): 3.6223518691258505e-06\n",
      "Outliers: []\n",
      "Minimum: -2.927061628951367\n",
      "First Quartile: 0.70359919027986\n",
      "Median: 1.209644289166277\n",
      "Third Quartile: 1.3444676423947557\n",
      "Maximum: 1.4976781982954304\n",
      "Interquartile Range: 0.6408684521148957\n",
      "Upper Bound (Outliers): 2.3057703205670994\n",
      "Lower Bound (Outliers): -0.25770348789248365\n",
      "Outliers: [-1.76169847 -1.76535501 -1.76352674 ... -0.46380831 -0.46746485\n",
      " -0.46563658]\n",
      "Minimum: 3.6225269468559418e-06\n",
      "First Quartile: 3.6225269468559418e-06\n",
      "Median: 3.6225269468559418e-06\n",
      "Third Quartile: 3.6225269468559418e-06\n",
      "Maximum: 3.6225269468559418e-06\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 3.6225269468559418e-06\n",
      "Lower Bound (Outliers): 3.6225269468559418e-06\n",
      "Outliers: []\n",
      "Minimum: 3.681200723804068e-06\n",
      "First Quartile: 3.681200723804068e-06\n",
      "Median: 3.681200723804068e-06\n",
      "Third Quartile: 3.681200723804068e-06\n",
      "Maximum: 3.681200723804068e-06\n",
      "Interquartile Range: 0.0\n",
      "Upper Bound (Outliers): 3.681200723804068e-06\n",
      "Lower Bound (Outliers): 3.681200723804068e-06\n",
      "Outliers: []\n",
      "Minimum: -3.029083798917791\n",
      "First Quartile: 0.7664939624838119\n",
      "Median: 1.3808143862638291\n",
      "Third Quartile: 1.400501415816993\n",
      "Maximum: 1.4433446032430193\n",
      "Interquartile Range: 0.6340074533331812\n",
      "Upper Bound (Outliers): 2.351512595816765\n",
      "Lower Bound (Outliers): -0.18451721751595995\n",
      "Outliers: [-1.74501315 -1.74860797 -1.74681056 ... -0.56270583 -0.56630065\n",
      " -0.56450324]\n"
     ]
    }
   ],
   "source": [
    "synth_ite_list = [ite_s, ite_t, ite_t_xgb, ite_t_lr, ite_x_p,  ite_x_p_lr, ite_x, ite_x_lr, ite_r, ite_r_p_lr, ite_r_pw_xgb, ite_r_no_p]\n",
    "y = 1\n",
    "for i in synth_ite_list:\n",
    "\n",
    "    # Calculate statistics\n",
    "    data = np.reshape(i, -1)\n",
    "    minimum = np.min(data)\n",
    "    first_quartile = np.percentile(data, 25)\n",
    "    median = np.median(data)\n",
    "    third_quartile = np.percentile(data, 75)\n",
    "    maximum = np.max(data)\n",
    "    \n",
    "    # Interquartile range (IQR)\n",
    "    iqr = third_quartile - first_quartile\n",
    "    \n",
    "    # Define upper and lower bounds for outliers\n",
    "    upper_bound = third_quartile + 1.5 * iqr\n",
    "    lower_bound = first_quartile - 1.5 * iqr\n",
    "    \n",
    "    # Detect outliers\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    # Print the statistics\n",
    "    print(\"Minimum:\", minimum)\n",
    "    print(\"First Quartile:\", first_quartile)\n",
    "    print(\"Median:\", median)\n",
    "    print(\"Third Quartile:\", third_quartile)\n",
    "    print(\"Maximum:\", maximum)\n",
    "    print(\"Interquartile Range:\", iqr)\n",
    "    print(\"Upper Bound (Outliers):\", upper_bound)\n",
    "    print(\"Lower Bound (Outliers):\", lower_bound)\n",
    "    print(\"Outliers:\", outliers)\n",
    "\n",
    "    exec(f'boxplot_synth_{y} = [minimum, first_quartile, median, third_quartile, maximum, iqr, upper_bound, lower_bound]')\n",
    "    y +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1198aeb8-c433-48df-aa7e-0f4f448df251",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_result_list = {'Method': ['S-Learner LR', 'XGBTRegressor', 'BaseTRegressor XGB', 'BaseTRegressor LR', 'BaseXRegressor XGB', 'BaseXRegressor LR',\n",
    "                          'BaseXRegressor XGB (without propensity score)','BaseXRegressor LR (without propensity score)', 'BaseRRegressor XGB', \n",
    "                          'BaseRRegressor LR', 'BaseRRegressor XGB (with random weight)', 'BaseRRegressor XGB (without propensity score)',\n",
    "                         'Neural Network (MLP)'],\n",
    "        'ATE': [ite_s.mean(), ite_t.mean(), ite_t_xgb.mean(), ite_t_lr.mean(), ite_x_p.mean(),  ite_x_p_lr.mean(), ite_x.mean(), ite_x_lr.mean(), ite_r.mean(), ite_r_p_lr.mean(), ite_r_pw_xgb.mean(), ite_r_no_p.mean(), te_nn[0]],\n",
    "        'ITE': [boxplot_synth_1, boxplot_synth_2, boxplot_synth_3, boxplot_synth_4, boxplot_synth_5,  boxplot_synth_6, boxplot_synth_7, boxplot_synth_8, boxplot_synth_9, boxplot_synth_10, boxplot_synth_11, boxplot_synth_12, ''],\n",
    "        'Metric': [metric_synth_1, metric_synth_2, metric_synth_3, metric_synth_4, metric_synth_5, metric_synth_6, metric_synth_7, metric_synth_8, metric_synth_9, metric_synth_10, metric_synth_11, metric_synth_12, '']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2024fae-5d7e-40e7-b5f3-bacff3cbf0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           method  \\\n",
      "0                                    S-Learner LR   \n",
      "1                                   XGBTRegressor   \n",
      "2                              BaseTRegressor XGB   \n",
      "3                               BaseTRegressor LR   \n",
      "4                              BaseXRegressor XGB   \n",
      "5                               BaseXRegressor LR   \n",
      "6   BaseXRegressor XGB (without propensity score)   \n",
      "7    BaseXRegressor LR (without propensity score)   \n",
      "8                              BaseRRegressor XGB   \n",
      "9                               BaseRRegressor LR   \n",
      "10        BaseRRegressor XGB (with random weight)   \n",
      "11  BaseRRegressor XGB (without propensity score)   \n",
      "12                           Neural Network (MLP)   \n",
      "\n",
      "                                                  ITE       ATE  \\\n",
      "0   [1.999999999999998, 1.9999999999999987, 1.9999...  2.000000   \n",
      "1            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "2            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "3            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "4            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "5            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "6            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "7            [2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0]  2.000000   \n",
      "8   [3.6223648294253508e-06, 3.6223648294253508e-0...  0.000004   \n",
      "9   [-2.9272906491754958, 0.7035801392352368, 1.20...  0.963643   \n",
      "10  [3.6222759263182525e-06, 3.6222759263182525e-0...  0.000004   \n",
      "11  [3.6812089092563838e-06, 3.6812089092563838e-0...  0.000004   \n",
      "12                                                     2.000000   \n",
      "\n",
      "                                              metrics  \n",
      "0   [1.698796199394374e-30, 1.2862177740158606e-15...  \n",
      "1                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "2                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "3                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "4                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "5                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "6                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "7                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "8   [3.9999855105538034, 1.9999963776351706, 1.999...  \n",
      "9   [1.415439487411538, 1.036357273412645, 1.18972...  \n",
      "10  [3.9999855109094153, 1.9999963777240737, 1.999...  \n",
      "11  [3.9999852751779157, 1.9999963187910907, 1.999...  \n",
      "12                                                     \n",
      "Stored 'df_synthetic_results_metric' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store -r df_synthetic_results_metric\n",
    "result_list = synth_result_list\n",
    "\n",
    "for i in range(len(result_list['Method'])):\n",
    "    method = result_list['Method'][i]\n",
    "    ate = result_list['ATE'][i]\n",
    "    ite = result_list['ITE'][i]\n",
    "    metric = result_list['Metric'][i]\n",
    "\n",
    "    df_synthetic_results_metric = df_synthetic_results_metric._append({'method': method, 'ATE': ate, 'ITE': ite, 'metrics': metric}, ignore_index=True)\n",
    "\n",
    "print(df_synthetic_results_metric)\n",
    "%store df_synthetic_results_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388cf26-9572-4905-9f7a-3b58ad676d7b",
   "metadata": {},
   "source": [
    "## Refutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8c28c5-60b5-4fc3-a434-4bf63780c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addRandomCauseDataset2.csv\n",
      "Average Treatment Effect:  0.019022724341103563\n",
      "addRandomCauseDataset1.csv\n",
      "Average Treatment Effect:  -0.003896047220189547\n",
      "Average ATE:  [0.019022724341103563, -0.003896047220189547]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Define folder path\n",
    "folder_path = \"./evaluationDatasets/Subset/\"\n",
    "\n",
    "# List to store treatment effects\n",
    "ate_values = []\n",
    "\n",
    "feature_names = ['NumberOfOffers', 'Action', 'org:resource',\n",
    "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
    "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'CreditScore', 'OfferedAmount', 'offerNumber','timeApplication', 'weekdayApplication']\n",
    "\n",
    "columns_to_drop = ['offerSuccess', 'treatmentOffer']\n",
    "\n",
    "# Iterate through files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print(file_name)\n",
    "    # Read CSV file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    refutation = pd.read_csv(file_path)\n",
    "\n",
    "    #X = refutation[feature_names]\n",
    "    X = refutation.drop(columns=columns_to_drop)    \n",
    "    y = refutation['offerSuccess']\n",
    "    treatment = refutation['treatmentOffer']\n",
    "    \n",
    "    nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "    te_nn, lb_nn, ub_nn = nn.estimate_ate(X, treatment, y)\n",
    "    print('Average Treatment Effect: ', te_nn[0])\n",
    "    ate_values.append(te_nn[0])\n",
    "\n",
    "print(\"Average ATE: \",ate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e26c54-d611-41bc-a181-02b7e0c45d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomReplacedDataset2.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5084008364086656\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.0797248317521689\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0021986893459338547\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.03122860087423773\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.002141273791038801\n",
      "randomReplacedDataset3.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5130356657056437\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07901551188124097\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.002713471899893684\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.030935816815594788\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.0017583169797670164\n",
      "randomReplacedDataset7.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5110942379859394\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07956531067948439\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0019896969701002445\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.03128344579512378\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.0009720271845218557\n",
      "randomReplacedDataset8.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5249182640231318\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.08474284078405961\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0016446546267247745\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.033471522967294706\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.000963199325517286\n",
      "randomReplacedDataset5.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5167486259570073\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07962597978485812\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0015911186709029372\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.031362124033431034\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.001549626278242967\n",
      "randomReplacedDataset4.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5123918757712885\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07308244830332375\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0025334594706897043\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.02431123199185515\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.0018218509271938873\n",
      "randomReplacedDataset6.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5098957991219156\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.08034326205841472\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.001126560628591052\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.032020610731647615\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.0010777636350303142\n",
      "randomReplacedDataset10.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5199606119173694\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.0800829373008353\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.001169236208530644\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.0316124594149822\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.002121930910821163\n",
      "randomReplacedDataset9.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5110942379859394\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07956531067948999\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0013567453307026483\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.03128462928726725\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.00222454045890073\n",
      "randomReplacedDataset1.csv\n",
      "Using the BaseXRegressor class and using XGB:\n",
      "0.5127197889197567\n",
      "\n",
      "Using the BaseXRegressor class and using Linear Regression:\n",
      "0.07962223066250879\n",
      "Using the BaseRRegressor class and using XGB:\n",
      "0.0027732894114844905\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "0.031390480904405216\n",
      "Using the BaseRRegressor class with random weight and using XGB:\n",
      "0.00263846548857891\n",
      "Average ATE\n",
      "0.5140259943796657\n",
      "0.07953706638863844\n",
      "0.0019096922563554036\n",
      "0.03089009228158394\n",
      "0.0017268994979612931\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Define folder path\n",
    "folder_path = \"./evaluationDatasets/Cause/\"\n",
    "\n",
    "# List to store treatment effects\n",
    "ate_r_pw_xgb_values = []\n",
    "ate_r_p_lr_values = []\n",
    "ate_r_p_xgb_values = []\n",
    "ate_x_p_lr_values = []\n",
    "ate_x_p_xgb_values = []\n",
    "\n",
    "feature_names = ['NumberOfOffers', 'Action', 'org:resource',\n",
    "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
    "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'CreditScore', 'OfferedAmount', 'offerNumber','timeApplication', 'weekdayApplication']\n",
    "\n",
    "columns_to_drop = ['offerSuccess', 'treatmentOffer']\n",
    "\n",
    "# Iterate through files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print(file_name)\n",
    "    # Read CSV file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    refutation = pd.read_csv(file_path)\n",
    "\n",
    "    #X = refutation[feature_names]\n",
    "    X = refutation.drop(columns=columns_to_drop)    \n",
    "    y = refutation['offerSuccess']\n",
    "    treatment = refutation['treatmentOffer']\n",
    "\n",
    "    p = np.load('propensity-score-MetaLearners.npy')\n",
    "\n",
    "    # X Learner with propensity score input\n",
    "    # Calling the Base Learner class and feeding in XGB\n",
    "    learner_x_p_xgb = BaseXRegressor(learner=XGBRegressor())\n",
    "    ate_x_p_xgb = learner_x_p_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "    print('Using the BaseXRegressor class and using XGB:')\n",
    "    print(ate_x_p_xgb[0][0])\n",
    "    ate_x_p_xgb_values.append(ate_x_p_xgb[0][0])\n",
    "    \n",
    "    # X Learner with propensity score input\n",
    "    # Calling the Base Learner class and feeding in LinearRegression\n",
    "    learner_x_p_lr = BaseXRegressor(learner=LinearRegression())\n",
    "    ate_x_p_lr = learner_x_p_lr.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "    print('\\nUsing the BaseXRegressor class and using Linear Regression:')\n",
    "    print(ate_x_p_lr[0][0])\n",
    "    ate_x_p_lr_values.append(ate_x_p_lr[0][0])\n",
    "    \n",
    "    # R Learner with propensity score input\n",
    "    # Calling the Base Learner class and feeding in XGB\n",
    "    learner_r_p_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "    ate_r_p_xgb = learner_r_p_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "    print('Using the BaseRRegressor class and using XGB:')\n",
    "    print(ate_r_p_xgb[0][0])\n",
    "    ate_r_p_xgb_values.append(ate_r_p_xgb[0][0])\n",
    "    \n",
    "    # R Learner with propensity score input\n",
    "    # Calling the Base Learner class and feeding in LinearRegression\n",
    "    learner_r_p_lr = BaseRRegressor(learner=LinearRegression())\n",
    "    ate_r_p_lr = learner_r_p_lr.estimate_ate(X=X, treatment=treatment, y=y, p=p)\n",
    "    print('Using the BaseRRegressor class and using Linear Regression:')\n",
    "    print(ate_r_p_lr[0][0])\n",
    "    ate_r_p_lr_values.append(ate_r_p_lr[0][0])\n",
    "    \n",
    "    # R Learner with propensity score input and random sample weight\n",
    "    # Calling the Base Learner class and feeding in XGB\n",
    "    learner_r_pw_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "    sample_weight = np.random.randint(1, 3, len(y))\n",
    "    ate_r_pw_xgb = learner_r_pw_xgb.estimate_ate(X=X, treatment=treatment, y=y, p=p, sample_weight=sample_weight)\n",
    "    print('Using the BaseRRegressor class with random weight and using XGB:')\n",
    "    print(ate_r_pw_xgb[0][0])\n",
    "    ate_r_pw_xgb_values.append(ate_r_pw_xgb[0][0])\n",
    "\n",
    "print(\"Average ATE\")\n",
    "print(sum(ate_x_p_xgb_values) / len(ate_x_p_xgb_values))\n",
    "print(sum(ate_x_p_lr_values) / len(ate_x_p_lr_values))\n",
    "print(sum(ate_r_p_xgb_values) / len(ate_r_p_xgb_values))\n",
    "print(sum(ate_r_p_lr_values) / len(ate_r_p_lr_values))\n",
    "print(sum(ate_r_pw_xgb_values) / len(ate_r_pw_xgb_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146bc2c-c01e-475f-90d9-060b1845bf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomReplacedDataset2.csv\n",
      "Using the S-Learner LinearRegression\n",
      "0.06480794448195776\n",
      "\n",
      "Using the XGBTRegressor class\n",
      "0.1825832869111424\n",
      "\n",
      "Using the BaseTRegressor class and using Linear Regression (different result):\n",
      "0.09420411477983939\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Define folder path\n",
    "folder_path = \"./evaluationDatasets/Replace/\"\n",
    "\n",
    "# List to store treatment effects\n",
    "ate_r_xgb_values = []\n",
    "ate_x_lr_values = []\n",
    "ate_x_xgb_values = []\n",
    "ate_t_lr_values = []\n",
    "ate_t_xgb_values = []\n",
    "ate_t_values = []\n",
    "ate_s_values = []\n",
    "\n",
    "feature_names = ['NumberOfOffers', 'Action', 'org:resource',\n",
    "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
    "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'CreditScore', 'OfferedAmount', 'offerNumber','timeApplication', 'weekdayApplication']\n",
    "\n",
    "columns_to_drop = ['offerSuccess', 'treatmentOffer']\n",
    "\n",
    "# Iterate through files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print(file_name)\n",
    "    # Read CSV file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    refutation = pd.read_csv(file_path)\n",
    "\n",
    "    #X = refutation[feature_names]\n",
    "    X = refutation.drop(columns=columns_to_drop)    \n",
    "    y = refutation['offerSuccess']\n",
    "    treatment = refutation['treatmentOffer']\n",
    "\n",
    "    # Ready-to-use S-Learner using LinearRegression\n",
    "    learner_s = LRSRegressor()\n",
    "    ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    print('Using the S-Learner LinearRegression')\n",
    "    print(ate_s[0][0])\n",
    "    ate_s_values.append(ate_s[0][0])\n",
    "    \n",
    "    # Ready-to-use T-Learner using XGB\n",
    "    learner_t = XGBTRegressor()\n",
    "    ate_t = learner_t.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    print('\\nUsing the XGBTRegressor class')\n",
    "    print(ate_t[0][0])\n",
    "    ate_t_values.append(ate_t[0][0])\n",
    "    \n",
    "    # Calling the Base Learner class and feeding in LinearRegression\n",
    "    learner_t_lr = BaseTRegressor(learner=LinearRegression())\n",
    "    ate_t_lr= learner_t_lr.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    print('\\nUsing the BaseTRegressor class and using Linear Regression (different result):')\n",
    "    print(ate_t_lr[0][0])\n",
    "    ate_t_lr_values.append(ate_t_lr[0][0])\n",
    "    \n",
    "    # X Learner without propensity score input\n",
    "    # Calling the Base Learner class and feeding in XGB\n",
    "    learner_x_xgb = BaseXRegressor(XGBRegressor())\n",
    "    ate_x_xgb = learner_x_xgb.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    print('Using the BaseXRegressor class and using XGB without propensity score input:')\n",
    "    print(ate_x_xgb[0][0])\n",
    "    ate_x_xgb_values.append(ate_x_xgb[0][0])\n",
    "    \n",
    "    # # X Learner without propensity score input\n",
    "    # # Calling the Base Learner class and feeding in LinearRegression\n",
    "    # learner_x_lr = BaseXRegressor(learner=LinearRegression())\n",
    "    # ate_x_lr = learner_x_lr.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    # print('\\nUsing the BaseXRegressor class and using Linear Regression without propensity score input:')\n",
    "    # print(ate_x_lr[0][0])\n",
    "    # ate_x_lr_values.append(ate_x_lr[0][0])\n",
    "    \n",
    "    # # R Learner without propensity score input\n",
    "    # # Calling the Base Learner class and feeding in XGB\n",
    "    # learner_r_xgb = BaseRRegressor(learner=XGBRegressor())\n",
    "    # ate_r_xgb = learner_r_xgb.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    # print('Using the BaseRRegressor class and using XGB without propensity score input:')\n",
    "    # print(ate_r_xgb[0][0])\n",
    "    # ate_r_xgb_values.append(ate_r_xgb[0][0])\n",
    "    \n",
    "\n",
    "print(\"Average ATE: \")\n",
    "print(sum(ate_r_xgb_values) / len(ate_r_xgb_values))\n",
    "print(sum(ate_x_lr_values) / len(ate_x_lr_values))\n",
    "print(sum(ate_x_xgb_values) / len(ate_x_xgb_values))\n",
    "print(sum(ate_t_lr_values) / len(ate_t_lr_values))\n",
    "print(sum(ate_t_values) / len(ate_t_values))\n",
    "print(sum(ate_s_values) / len(ate_s_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dowhy",
   "language": "python",
   "name": "dowhy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
