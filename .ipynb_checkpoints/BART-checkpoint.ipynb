{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667579c2-ecbc-4b09-a8ce-bf2e3b669623",
   "metadata": {},
   "source": [
    "Accelerated Bayesian Causal Forest\n",
    "https://johaupt.github.io/blog/xbcf.html\n",
    "\n",
    "Accelerated Bayesian Causal Forest (XBCF) to estimate the conditional average treatment effect (or uplift) using a specialized version of Bayesian Additive Regression Trees (BART). Itâ€™s better described as Bayesian boosted trees for non-parametric causal inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745ad78f-b583-44bc-a860-0fa4a13262c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xbcausalforest import XBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a723eb1e-39ae-45da-8114-a558c2222b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bpi2017_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68aac10-373e-4efe-8528-43776b46739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['NumberOfOffers', 'Action', 'org:resource',\n",
    "       'concept:name', 'EventOrigin', 'lifecycle:transition', 'time:timestamp',\n",
    "       'case:LoanGoal', 'case:ApplicationType', 'case:RequestedAmount',\n",
    "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
    "       'CreditScore', 'OfferedAmount', 'offerNumber','timeApplication', 'weekdayApplication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde3a0fd-7f22-4066-9e88-7424475acd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing samples for model validation (next section)\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=11101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b17ec1-7208-4b25-8ab0-c392190d31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment=df_train['treatmentOffer']\n",
    "X = df_train[feature_names]\n",
    "y=df_train['offerSuccess']\n",
    "\n",
    "treatment_test=df_test['treatmentOffer']\n",
    "X_test = df_test[feature_names]\n",
    "y_test=df_test['offerSuccess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3e664c-127f-4aa0-9353-0dff5b0f6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TREES_PR  = 200\n",
    "NUM_TREES_TRT = 100\n",
    "\n",
    "cf = XBCF(\n",
    "    #model=\"Normal\",\n",
    "    parallel=True, \n",
    "    num_sweeps=50, \n",
    "    burnin=15,\n",
    "    max_depth=250,\n",
    "    num_trees_pr=NUM_TREES_PR,\n",
    "    num_trees_trt=NUM_TREES_TRT,\n",
    "    num_cutpoints=100,\n",
    "    Nmin=1,\n",
    "    #mtry_pr=X1.shape[1], # default 0 seems to be 'all'\n",
    "    #mtry_trt=X.shape[1], \n",
    "    tau_pr = 0.6 * np.var(y)/NUM_TREES_PR, #0.6 * np.var(y) / /NUM_TREES_PR,\n",
    "    tau_trt = 0.1 * np.var(y)/NUM_TREES_TRT, #0.1 * np.var(y) / /NUM_TREES_TRT,\n",
    "    alpha_pr= 0.95, # shrinkage (splitting probability)\n",
    "    beta_pr= 2, # shrinkage (tree depth)\n",
    "    alpha_trt= 0.95, # shrinkage for treatment part\n",
    "    beta_trt= 2,\n",
    "    p_categorical_pr = 0,\n",
    "    p_categorical_trt = 0,\n",
    "    standardize_target=True, # standardize y and unstandardize for prediction\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551935a8-4688-4d43-9ab3-f0ecc942c287",
   "metadata": {},
   "source": [
    "Since we specify the model as a sum of two BARTs, we can pass different sets of covariates to the outcome model and the treatment model, denoted by x and x_t. z is the treatment indicator coded 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf4ccc-5c18-49f8-88ed-5bbf6e13106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cf.fit(\n",
    "    x_t=X, # Covariates treatment effect\n",
    "    x=X, # Covariates outcome (including propensity score)\n",
    "    y=y,  # Outcome\n",
    "    z=treatment, # Treatment group\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b3bcc-04c8-4e51-b9c0-9db9cb2319d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tau_xbcf = cf.predict(X_test, return_mean=True)\n",
    "tau_xbcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c29f1-eb73-4a9d-9c00-433e00ea8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "data = np.reshape(tau_xbcf, -1)\n",
    "minimum = np.min(data)\n",
    "first_quartile = np.percentile(data, 25)\n",
    "median = np.median(data)\n",
    "third_quartile = np.percentile(data, 75)\n",
    "maximum = np.max(data)\n",
    "\n",
    "# Interquartile range (IQR)\n",
    "iqr = third_quartile - first_quartile\n",
    "\n",
    "# Define upper and lower bounds for outliers\n",
    "upper_bound = third_quartile + 1.5 * iqr\n",
    "lower_bound = first_quartile - 1.5 * iqr\n",
    "\n",
    "# Detect outliers\n",
    "outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Minimum:\", minimum)\n",
    "print(\"First Quartile:\", first_quartile)\n",
    "print(\"Median:\", median)\n",
    "print(\"Third Quartile:\", third_quartile)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Interquartile Range:\", iqr)\n",
    "print(\"Upper Bound (Outliers):\", upper_bound)\n",
    "print(\"Lower Bound (Outliers):\", lower_bound)\n",
    "print(\"Outliers:\", outliers)\n",
    "\n",
    "ite_bart = [minimum, first_quartile, median, third_quartile, maximum, iqr, upper_bound, lower_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246df696-f942-4081-b82d-ae8f4e769914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_results\n",
    "lib = \"xbcausalforest\"\n",
    "method = \"Accelerated Bayesian Causal Forest\"\n",
    "ite = ite_bart\n",
    "ate = tau_xbcf.mean()\n",
    "\n",
    "if method in df_results['method'].values:\n",
    "     # If the method is already in the DataFrame, update the ATE and ITE columns\n",
    "    df_results.loc[df_results['method'] == method, 'ATE'] = ate\n",
    "    index = df_results[df_results['method'] == method].index[0]\n",
    "    df_results.at[index, 'ITE'] = ite\n",
    "else:\n",
    "    # If the method is not in the DataFrame, add a new row\n",
    "    df_results = df_results._append({'method': method, 'ATE': ate, 'ITE': ite, 'Library': lib}, ignore_index=True)\n",
    "\n",
    "print(df_results)\n",
    "%store df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bart",
   "language": "python",
   "name": "bart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
